{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets & DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for preprocessing data samples can get messy and hard to maintain; we ideally want our dataset code to be decoupled from our model training code for better readability and modularity.\n",
    "\n",
    "PyTorch provides two data primitives: <i><b>torch.utils.data.DataLoader</i></b> and <i><b>torch.utils.data.Dataset</i></b> that allow you to use pre-loaded datasets as well as your own data.\n",
    "\n",
    "<i><b>Dataset</i></b> stores the samples and their corresponding labels, and <b><i>DataLoader</i></b> wraps an iterable around the Dataset to enable easy access to the samples. \n",
    "\n",
    "\n",
    "PyTorch domain libraries provide a number of pre-loaded datasets (such as FashionMNIST) that subclass <b><i>torch.utils.data.Dataset</i></b> and implement functions specific to the particular data. They can be used to prototype and benchmark your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use our own data to learn how to load it. The data used will be the California Housing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  \n",
       "0    -122.23  \n",
       "1    -122.22  \n",
       "2    -122.24  \n",
       "3    -122.25  \n",
       "4    -122.25  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.526\n",
       "1    3.585\n",
       "2    3.521\n",
       "3    3.413\n",
       "4    3.422\n",
       "Name: MedHouseVal, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now in the deep-learning realm, so let's cast everything into PyTorch tensors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.set_printoptions(sci_mode=False, linewidth=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X.to_numpy()).float()\n",
    "y = torch.from_numpy(y.to_numpy()).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20640, 8]), torch.Size([20640]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 20640 samples and 8 features\n",
    "X.size(), y.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A note on dtype: in NumPy, the default <i><b>dtype</i></b> is usually <i><b>np.float64</i></b> (also known as the <i><b>double</i></b> type). But in PyTorch the default is </i></b>torch.float32<i><b> (also known as the <i><b>float</i></b>type). \n",
    "\n",
    "Computations performed in double precisions are often much slover and more memory-intensive than that in single precisions, even on a GPU. Moreover, the additional precision offered by <i><b>double</i></b> usually doesn't matter (i.e., it won't affect the evaluation metrics). That's why we cast <i><b>x</i></b> and <i><b>y</i></b> to <i><b>torch.float32</i></b> using <i><b>.float()</i></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a custom Dataset\n",
    "\n",
    "When your data is already stored as tensors, TensorDataset will come in handy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "cal_housing = TensorDataset(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we need a Dataset? Because it allows us to index into our tensors and retrieve (features, label) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   8.3252,   41.0000,    6.9841,    1.0238,  322.0000,    2.5556,   37.8800, -122.2300]),\n",
       " tensor(4.5260))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_housing[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[     8.3252,     41.0000,      6.9841,      1.0238,    322.0000,      2.5556,     37.8800,   -122.2300],\n",
       "         [     8.3014,     21.0000,      6.2381,      0.9719,   2401.0000,      2.1098,     37.8600,   -122.2200],\n",
       "         [     7.2574,     52.0000,      8.2881,      1.0734,    496.0000,      2.8023,     37.8500,   -122.2400],\n",
       "         [     5.6431,     52.0000,      5.8174,      1.0731,    558.0000,      2.5479,     37.8500,   -122.2500],\n",
       "         [     3.8462,     52.0000,      6.2819,      1.0811,    565.0000,      2.1815,     37.8500,   -122.2500]]),\n",
       " tensor([4.5260, 3.5850, 3.5210, 3.4130, 3.4220]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_housing[:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20640"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cal_housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can split our dataset into training and testing sets using PyTorch's <i><b>random_split</i></b> function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "train_frac = 0.73 \n",
    "train_size = math.floor(train_frac * len(cal_housing)) # floor because the size has to be an int\n",
    "test_size = len(cal_housing) - train_size\n",
    "\n",
    "cal_housing_train, cal_housing_test = random_split(cal_housing, (train_size, test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15067, 5573)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cal_housing_train), len(cal_housing_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepraring your data for training with DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <i><b>Dataset</i></b> retrieves our dataset's features and labels on sample at a time. While training a model, we typically want to pass samples in \"minibatches\", reshuffle the data at every epoch to reduce model overfitting, and use Python's <i><b>multipreprocessing</i></b> to speed up data retrieval. \n",
    "\n",
    "<i><b>DataLoader</i></b> is an iterable that abstracts this complexity for us in an easy API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(cal_housing_train, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(cal_housing_test, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterate through the DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have loaded that dataset into the <i><b>DataLoader</i></b> and can iterate through the dataset as needed. Each iteration below returns a batch of <i><b>train_features</i></b> and <i><b>train_labels</i></b> (containing <i><b>batch_size = 64</i></b> features and labels respectively). Because we specified <i><b>shuffle=True</i></b>, after we iterate over all batches the data is shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[     4.0223,     33.0000,      5.0475,      1.0289,   1601.0000,      3.3079,     34.3000,   -118.4300],\n",
      "        [     4.1717,     33.0000,      4.9853,      1.1187,   2701.0000,      1.8007,     34.1100,   -118.3500],\n",
      "        [     9.3092,     39.0000,      7.2343,      1.1162,    975.0000,      1.8571,     34.1000,   -118.3800],\n",
      "        [     2.5132,     44.0000,      4.9402,      1.0370,   1133.0000,      3.2279,     34.0600,   -118.1900],\n",
      "        [     2.1513,      8.0000,      8.1178,      1.5589,    786.0000,      2.6465,     40.6100,   -121.6700],\n",
      "        [     1.6685,     28.0000,      3.7382,      0.9717,   1362.0000,      3.2123,     38.4300,   -122.7000],\n",
      "        [     2.3382,     19.0000,      4.0599,      1.0526,   1438.0000,      2.6098,     37.9700,   -122.3400],\n",
      "        [     6.6204,     16.0000,      6.7293,      0.9658,   2464.0000,      3.2378,     37.7500,   -121.9400],\n",
      "        [     4.1449,     37.0000,      5.7692,      1.0533,   1183.0000,      3.5000,     33.9300,   -118.0900],\n",
      "        [     4.0662,     52.0000,      5.5781,      1.0469,    440.0000,      2.2917,     37.7400,   -122.1400],\n",
      "        [     1.4464,     17.0000,      5.4310,      1.5345,    130.0000,      2.2414,     37.6500,   -120.4600],\n",
      "        [     2.5139,     30.0000,      4.3247,      1.1389,   1091.0000,      1.8941,     34.4300,   -119.7200],\n",
      "        [     2.8261,     19.0000,      4.3416,      0.9826,   1782.0000,      2.5901,     38.3400,   -122.7000],\n",
      "        [     3.6181,     21.0000,      5.0761,      1.0131,    861.0000,      2.2598,     33.2100,   -117.2300],\n",
      "        [     2.6684,     50.0000,      3.5446,      1.0388,   1129.0000,      2.1880,     37.8700,   -122.2900],\n",
      "        [     3.9808,     35.0000,      5.3100,      0.9631,    804.0000,      2.9668,     34.0700,   -117.8900],\n",
      "        [     2.1250,     26.0000,     37.0635,      7.1852,    416.0000,      2.2011,     38.1900,   -120.0300],\n",
      "        [     3.7279,     36.0000,      5.4472,      1.0151,    920.0000,      4.6231,     34.0500,   -118.0500],\n",
      "        [     6.9737,     31.0000,      7.0414,      0.9807,   1044.0000,      2.8840,     33.7700,   -117.8800],\n",
      "        [     5.9088,      5.0000,      5.8806,      1.1010,   2834.0000,      2.4881,     33.5300,   -117.7000],\n",
      "        [     5.3238,      8.0000,      7.8316,      1.2115,   9360.0000,      2.7849,     33.6800,   -117.2700],\n",
      "        [     2.7321,     31.0000,      4.7034,      1.1144,   1662.0000,      3.5212,     34.0500,   -117.7200],\n",
      "        [     2.6217,     36.0000,      3.7921,      1.0293,   2846.0000,      3.6301,     34.1600,   -118.1400],\n",
      "        [     2.8661,     36.0000,      4.6455,      1.0366,   2392.0000,      3.8029,     34.0700,   -117.7700],\n",
      "        [     5.5658,     52.0000,      5.3000,      0.9841,   1135.0000,      2.5795,     34.1700,   -118.2800],\n",
      "        [     3.9798,     31.0000,      4.7073,      1.1122,   1002.0000,      2.4439,     34.0000,   -118.4200],\n",
      "        [     3.3750,     37.0000,      4.0542,      1.0047,   1266.0000,      2.9858,     33.8900,   -118.3600],\n",
      "        [     5.9094,      5.0000,      6.5742,      1.1081,   7417.0000,      3.1455,     33.0000,   -117.1000],\n",
      "        [     2.6181,      9.0000,      5.0775,      1.4793,    851.0000,      1.5333,     32.7500,   -117.1500],\n",
      "        [     1.6071,     44.0000,      3.8625,      1.5125,    315.0000,      3.9375,     36.6500,   -121.6300],\n",
      "        [     5.3264,     46.0000,      4.9412,      1.0956,    351.0000,      2.5809,     37.5100,   -122.2600],\n",
      "        [     1.8750,     33.0000,    141.9091,     25.6364,     30.0000,      2.7273,     38.9100,   -120.1000],\n",
      "        [     2.8281,     29.0000,      5.1168,      1.0872,   1530.0000,      2.5164,     34.8900,   -117.0200],\n",
      "        [     3.1779,     16.0000,      4.6362,      0.9608,   1860.0000,      4.0523,     38.0400,   -121.2900],\n",
      "        [     2.5313,     37.0000,      3.3800,      1.0900,    231.0000,      2.3100,     36.6300,   -121.8600],\n",
      "        [     4.2464,     16.0000,      6.0074,      0.9816,   1794.0000,      3.3039,     38.7000,   -121.2500],\n",
      "        [     1.5517,     31.0000,      3.1108,      0.9748,    816.0000,      2.0554,     32.7600,   -117.0900],\n",
      "        [     3.9375,     24.0000,      7.6627,      1.1953,   1093.0000,      3.2337,     34.8700,   -120.3300],\n",
      "        [     2.6316,     34.0000,      5.4121,      1.2915,    478.0000,      2.4020,     34.1400,   -118.0200],\n",
      "        [     1.8937,     21.0000,      3.7345,      1.0827,   4868.0000,      2.2995,     32.8000,   -116.9400],\n",
      "        [     2.3056,     43.0000,      5.1934,      1.1492,    690.0000,      3.8122,     37.9600,   -121.2600],\n",
      "        [     2.5000,     37.0000,      4.7939,      1.0473,   1125.0000,      3.8007,     33.9900,   -118.0800],\n",
      "        [     6.0808,     35.0000,      4.9691,      0.9416,    759.0000,      2.6082,     34.2700,   -118.3100],\n",
      "        [     2.2656,     15.0000,      4.7554,      1.1322,   2383.0000,      2.0455,     35.2600,   -120.6600],\n",
      "        [     5.5388,     25.0000,      6.1045,      1.0138,   1251.0000,      2.4675,     37.3500,   -122.0300],\n",
      "        [     2.4943,     45.0000,      4.4474,      1.0865,    900.0000,      3.3835,     32.6800,   -117.1000],\n",
      "        [     4.2062,     37.0000,      5.4419,      0.9961,    652.0000,      2.5271,     33.8600,   -118.1400],\n",
      "        [    15.0001,     32.0000,      8.8450,      1.0351,   1318.0000,      2.7231,     37.4400,   -122.2200],\n",
      "        [     2.3175,     26.0000,      3.8136,      1.0382,   8551.0000,      4.7295,     33.9700,   -118.1800],\n",
      "        [     5.2134,     13.0000,      7.5641,      1.0897,   1055.0000,      3.3814,     36.3600,   -119.6400],\n",
      "        [     3.1204,     44.0000,      5.2958,      1.0587,   1057.0000,      2.4812,     38.1000,   -122.2200],\n",
      "        [     2.7757,     17.0000,      5.2679,      1.1333,   2544.0000,      3.2615,     34.1100,   -117.4300],\n",
      "        [     3.8438,     28.0000,      5.4224,      1.1205,   3502.0000,      3.6709,     34.0800,   -117.7300],\n",
      "        [     7.5426,     19.0000,      5.4122,      1.0338,   2927.0000,      1.9031,     33.9800,   -118.4300],\n",
      "        [     5.1354,     26.0000,      6.9246,      1.0603,   1166.0000,      2.9296,     32.6300,   -117.0400],\n",
      "        [     2.6623,     32.0000,      5.1161,      1.1147,   1452.0000,      2.0308,     38.6300,   -121.3700],\n",
      "        [     5.0000,     24.0000,      4.4928,      0.9529,    690.0000,      2.5000,     37.2900,   -121.9600],\n",
      "        [     4.0724,     25.0000,      5.0078,      1.0753,    961.0000,      2.4961,     33.8400,   -117.8700],\n",
      "        [     3.3937,     52.0000,      4.0957,      1.1078,   2280.0000,      2.1190,     37.7600,   -122.4200],\n",
      "        [     2.3173,     25.0000,      4.9153,      1.1157,   1482.0000,      3.0620,     36.8200,   -119.7000],\n",
      "        [     2.4632,     41.0000,      5.3094,      1.0288,   1086.0000,      3.9065,     33.8900,   -118.2500],\n",
      "        [     2.4931,     32.0000,      4.3164,      1.0982,   1003.0000,      3.6473,     33.8200,   -117.9000],\n",
      "        [     4.3862,     33.0000,      5.6485,      1.0331,   1954.0000,      2.3124,     32.8100,   -117.2100],\n",
      "        [     3.2216,     34.0000,      6.2526,      1.0493,   1891.0000,      2.8266,     40.8600,   -124.0600]])\n",
      "tensor([1.4600, 5.0000, 5.0000, 1.6310, 0.8040, 1.1410, 1.2070, 2.9610, 1.7530, 2.0420, 0.7920, 2.7950, 1.5450, 2.1380, 1.8560, 1.8860, 1.3250, 1.6220, 2.8880, 2.8850, 2.2890, 1.0430, 1.5630, 1.2400, 3.3120, 4.5860, 2.2800, 2.6110, 2.0420, 1.1250, 2.5810, 5.0000, 0.6930, 0.9730, 1.0830, 1.4440,\n",
      "        1.2250, 3.4120, 2.5280, 1.0980, 0.6230, 1.6200, 2.1560, 2.2620, 3.5210, 0.9960, 1.9540, 5.0000, 1.5450, 0.9740, 1.1080, 1.0980, 1.3080, 3.5170, 1.8160, 1.2070, 2.8300, 2.3140, 2.7000, 0.6820, 1.1170, 1.6690, 1.8480, 0.9810])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "\n",
    "\n",
    "print(train_features)\n",
    "print(train_labels)\n",
    "\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><b>next</i></b> + <i><b>iter</i></b> is useful when you want to examine a batch of data (e.g., to check if you have implemented your data-loading functions correctly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But a more common paradigm is to use your <i><b>DataLoader<i><b> with a <i><b>for<i><b> loop, so that you can continously step into your batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([64, 8])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Feature batch shape: torch.Size([5, 8])\n",
      "Labels batch shape: torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "for features, labels in test_dataloader:\n",
    "    print(f\"Feature batch shape: {features.size()}\")\n",
    "    print(f\"Labels batch shape: {labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
